# WARNING THIS SCRIPT IS ORIGINALLY GENERATED BY CHATGPT4o

# PATHS ARE EXPECTING THIS TO BE CALLED FROM DJ_Intern_Code/notebooks

import os, glob
from pathlib import Path
from time import time
from tqdm import tqdm
import subprocess
import itertools
import pandas as pd
import numpy as np
from multiprocessing import Pool, cpu_count
from functools import partial
import platform
import MDAnalysis as mda
from MDAnalysis.coordinates import PDB
"""
TM-score and meaning:

1.0 = perfect structural match (identical structures)
< 0.2 â‰ˆ random similarity
> 0.5 = typically indicates same fold
> 0.8 = often considered nearly identical structures (small conformational shifts only)
"""
def _rp_nmr_dir():
    return os.path.join('..', 'data', 'NMR')


def _rp_tmscores_dir():
    return os.path.join(_rp_nmr_dir(), 'TMscores')


def _rp_mean_coords_input_dir(sub_dir: str):
    return os.path.join(_rp_nmr_dir(), 'RMSD', sub_dir, 'mean_coords')


def _read_all_pdbs_from_txt(txt_f: str) -> list:
    rp_pidchains_lst_f = os.path.join('..', 'data', 'NMR', 'multimodel_lists', txt_f)
    if 'singlemod' == txt_f.split('_')[1]:
        with open(rp_pidchains_lst_f, 'r') as f:
            next(f)  # ignore first line
            pidchains = f.read().split()
    else:
        with open(rp_pidchains_lst_f, 'r') as f:
            pidchains = f.read().split('\n')
            pidchains = pidchains[:-1]
    rp_pdb_files = []
    PDB_dir = os.path.join('..', 'data', 'NMR', 'pdb_chains', 'hethom_combined')
    for pidchain in pidchains:
        rp_pdb_files.append(os.path.join(PDB_dir, f'{pidchain}.pdb'))
    return rp_pdb_files

op_sys = platform.system()  # 'Linux', 'Darwin' (Darwin = macOS), or 'Windows'
TMALIGN_BIN = os.path.join('utils', op_sys, 'TMalign')

def compute_tm(rp_pdb1, rp_pdb2):
    """
    Note: TM-score, unlike my RMSD calculation, does not take in arrays of coordinates.
    Instead, it expects (valid) PDB files.
    Compute TM-score between two pdb files.
    """

    try:
        result = subprocess.run(
            [TMALIGN_BIN, rp_pdb1, rp_pdb2],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            timeout=60
        )
        output = result.stdout
        for line in output.splitlines():
            if line.startswith('TM-score='):
                tm = float(line.split('=')[1].split()[0])
                return tm
    except Exception as e:
        print(f'Error computing TM-score for {rp_pdb1} vs {rp_pdb2}: {e}')
        return np.nan


def compute_tm_from_mp_pool(idx_pair, rp_all_pdb_files):
    """
    Takes a pair of integers, used as indexes to the list of PDB files (given as the relative path strings to the
    appropriate PDB/PDBchain files (which are expected to be single model, or a single mean of all models).)
    Compute TM-score between each pair of PDB/PDBchain files.
    """
    f1_idx, f2_idx = idx_pair
    f1 = rp_all_pdb_files[f1_idx]
    f2 = rp_all_pdb_files[f2_idx]
    f1_pdbname = os.path.basename(f1).removesuffix('.pdb')
    f2_pdbname = os.path.basename(f2).removesuffix('.pdb')

    assert Path(TMALIGN_BIN).exists(), f'{TMALIGN_BIN} does not exist'
    assert os.path.isfile(f1), f'{f1} not found'
    assert os.path.isfile(f2), f'{f2} not found'
    try:
        result = subprocess.run(
            [TMALIGN_BIN, f1, f2],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            timeout=60
        )
        output = result.stdout
        for line in output.splitlines():
            if line.startswith('TM-score='):
                tm = float(line.split('=')[1].split()[0])
                print(f'\nTM-score={tm} for {f1_pdbname}:{f2_pdbname}')
                return f1_pdbname, f2_pdbname, tm
    except Exception as e:
        print(f'Error computing TM-score for {f1} vs {f2}: {e}')
        return f1_idx, f2_idx, np.nan


def _write_mean_coords_to_pdb(rp_pdb_f: str) -> None:
    """
    Using MDAnalysis to calculate mean coords of given PDB/PDBchain file and write out to PDB/PDBchain file.
    Note: the PDB it writes out:
     - starts with 'MODEL 1' even though its an average of all the models.
     - lacks 'MASTER' at end and 'TER' at terminus.
    I assume it is still a valid PDB as it seems unlikely to me that this is an error by MDAnalysis.
    # TODO: Might need to either calculate the means and write each PDB/PDBchain manually myself,
    # TODO: OR just edit these files to add the 'MASTER' and 'TER' to each PDB/PDBchain file.
    """
    u = mda.Universe(rp_pdb_f)
    n_atoms = len(u.atoms)
    coords_per_model = []  # store coords per model
    for _ in u.trajectory:  # iterate through each model
        coords_per_model.append(u.atoms.positions.copy())
    coords_array = np.array(coords_per_model)  # shape=(n_models, n_atoms, 3)
    mean_coords = coords_array.mean(axis=0)  # mean coords over all models
    u.atoms.positions = mean_coords  # set mean coords into "Universe"
    with mda.Writer(os.path.basename(rp_pdb_f), n_atoms) as W:
        W.write(u.atoms)


def _write_PDB_HETATMout_CAonly(rp_pdf_f: str, rp_dst_parsed_pdbs_dir: str) -> None:
    pidc = os.path.basename(rp_pdf_f).removeprefix('.pdb')
    print(pidc)
    u = mda.Universe(rp_pdf_f)  # can also be .cif
    ca_atoms = u.select_atoms('protein and name CA') # standard residues (no HETATM) and alpha-carbons only.

    rp_parsed_pdb_f = os.path.join(rp_dst_parsed_pdbs_dir, f'{pidc}')
    with mda.Writer(rp_parsed_pdb_f, ca_atoms.n_atoms) as writer:
        writer.write(ca_atoms)


if __name__ == '__main__':

    start = time()
    # # 1. IN PREP FOR RUNNING TM-ALIGN ON ALL MULTIMODEL PDBCHAIN FILES, PARSE, CALC MEAN COORDS & WRITE TO PDB FILES:
    # # 1.1. PARSE ALL MULTIMODEL PDBCHAINS (ACCORDING TO MULTIMODEL PDBCHAINS LIST) & WRITE TO PDB FILES:
    rp_dst_parsed_pdbs_dir_ = os.path.join(_rp_nmr_dir(), 'pdb_chains', 'parsed', 'multimod_hetallchains_hom1chain')
    os.makedirs(rp_dst_parsed_pdbs_dir_, exist_ok=True)

    with open(os.path.join(_rp_nmr_dir(), 'multimodel_lists', 'multimod_2713_hetallchains_hom1chain.lst'), 'r') as f:
        pidchains = f.read().splitlines()
    pidchains.sort()
    print(len(pidchains))  # should be 2713

    rp_pdb_dir = os.path.join(_rp_nmr_dir(), 'pdb_chains', 'hethom_combined')
    os.makedirs(rp_pdb_dir, exist_ok=True)

    for pidchain in pidchains:
        rp_pdb_f_ = os.path.join(rp_pdb_dir, f'{pidchain}.pdb')
        _write_PDB_HETATMout_CAonly(rp_pdb_f_, rp_dst_parsed_pdbs_dir_)

    # # 1.2. CALCULATE MEAN COORDINATES OF ALL PARSED PDBCHAIN FILES AND WRITE OUT TO PDB FILES:
    rp_parsed_pdbchain_dir = os.path.join(_rp_nmr_dir(), 'pdb_chains', 'parsed', 'multimod_hetallchains_hom1chain')
    rp_dst_mean_coords_pdb_dir = os.path.join(rp_parsed_pdbchain_dir, 'mean_coords')

    rp_parsed_pdbchains_files = sorted(glob.glob(os.path.join(rp_parsed_pdbchain_dir, '*.pdb')))
    print(len(rp_parsed_pdbchains_files))  # should be 2713
    for rp_pdb_f_ in rp_parsed_pdbchains_files:
        _write_mean_coords_to_pdb(rp_pdb_f_)

    # # 2. CALCULATE TM-SCORES OF ALL VS ALL FOR PARSED PDBCHAINS (USING MEAN COORDS PDB FILES):
    # rp_mean_coords_pdb_dir = os.path.join(_rp_nmr_dir(), 'pdb_chains', 'parsed', 'multimod_hetallchains_hom1chain',
    #                                       'mean_coords')
    # rp_parsed_mean_coords_pdbchains_files = sorted(glob.glob(os.path.join(rp_mean_coords_pdb_dir, '*.pdb')))
    #
    # N = len(rp_parsed_mean_coords_pdbchains_files)
    # print(f'Found {N} PDB/PDBchain files in parsed/... /mean_coords dir.') # Should be 2713
    #
    # # Generate all unique integer pair combinations (i < j) for above number of PDB files:
    # pairs = list(itertools.combinations(range(N), 2))
    # print(f'Total pairs to compute: {len(pairs)}')  # Total pairs to compute: 6320790
    #
    # # Number of worker processes
    # n_workers = max(cpu_count() - 1, 1)
    # print(f'Using {n_workers} parallel workers.')  # Using 9 parallel workers.
    #
    # # Bind the extra argument
    # # _compute_tm = partial(compute_tm, pdb_files=pdb_files_)
    # _compute_tm = partial(compute_tm_from_mp_pool, rp_all_pdb_files=rp_all_pdb_files)
    #
    # # List to store only interesting results
    # results = {'query': [], 'target': [], 'TMscore': []}
    #
    # with Pool(processes=n_workers) as pool:
    #     for result_ in tqdm(
    #             pool.imap_unordered(_compute_tm, pairs, chunksize=10),
    #             total=len(pairs), desc="Processing TM-scores"
    #     ):
    #         pdb1, pdb2, tms = result_
    #         if np.isnan(tms):
    #             continue
    #         # if tm_ <= 0.8:
    #         results['query'].append(pdb1)
    #         results['target'].append(pdb2)
    #         results['TMscore'].append(tms)
    # res_pdf = pd.DataFrame(results)
    # res_pdf.to_csv(os.path.join('..', 'data', 'TM-scores.csv'), index=False)
    #
    # # Save interesting pairs as .npy
    # rp_dst_tmalign_dir = _rp_tmscores_dir()
    # os.makedirs(rp_dst_tmalign_dir, exist_ok=True)
    # rp_tm_pairs = os.path.join(rp_dst_tmalign_dir, 'all_vs_all_TMS.npy')
    # print(f'Completed in {round((time() - start) / 60)} minutes.')





    # rp_multimod_pdb = '../data/NMR/raw_pdbs/hethom_combined/1A0N.pdb'
    # write_mean_coords_to_pdb(rp_multimod_pdb)
    # rp_singlemod_pdb = '../data/NMR/raw_pdbs/hethom_combined/1FU5.pdb'
    # write_mean_coords_to_pdb(rp_singlemod_pdb)

    # mmseqs2_results_dir =mmseqs2.rp_mmseqs_results_dir(het_hom='hethom_combined')
    # homologues = pd.read_csv(os.path.join(mmseqs2_results_dir, 'homologues_30_20_90.csv'))
    # non_homologues = pd.read_csv(os.path.join(mmseqs2_results_dir, 'non_homologues_30_20_90.csv'))
    # prefix = os.path.join('..', 'data', 'NMR', 'raw_pdbs', 'hethom_combined')
    # suffix = '.pdb'

    # pdbid_chain = '1cvr_A'
    # PDB_DIR = os.path.join('', 'data', 'ATLAS_parsed', pdbid_chain, 'CA_only')
    # # PDB_DIR = os.path.join('..', 'data', 'ATLAS_parsed', pdbid_chain, 'test')
    # pdb_files_100_spread = [pdb_f for idx, pdb_f in enumerate(pdb_files_) if idx % 100 == 0]
    # assert(len(pdb_files_100_spread) == 101)

    # # Save interesting pairs as .npy
    # rpath_tm_pairs = os.path.join('', 'data', 'ATLAS_parsed', pdbid_chain, 'low_tm_pairs.npy')
    # np.save(rpath_tm_pairs, np.array(interesting_results, dtype=object))
    # print(f"Saved {len(interesting_results)} pairs with TM-score < 0.8 to {rpath_tm_pairs}.")
    # print(f'Completed in {round((time() - start) / 60)} minutes.')