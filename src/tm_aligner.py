# WARNING THIS SCRIPT IS ORIGINALLY GENERATED BY CHATGPT4o

# PATHS ARE EXPECTING THIS TO BE CALLED FROM DJ_Intern_Code/notebooks

import os, glob
from pathlib import Path
from time import time
from tqdm import tqdm
import subprocess
import itertools
import statistics
import pandas as pd
import numpy as np
from multiprocessing import Pool, cpu_count
from functools import partial
import platform


"""(CGT4o)

TM-score and interpretation:

  1.0 = perfect structural match (identical structures)
> 0.8 = often considered nearly identical structures (small conformational shifts only)
> 0.5 = typically indicates same fold
< 0.2 ≈ random similarity
"""


def _rp_nmr_dir() -> str:
    return os.path.join('..', 'data', 'NMR')


def _rp_tmscores_dir(sub_dir: str) -> str:
    return os.path.join(_rp_nmr_dir(), 'TMscores', sub_dir)


def _read_all_pdbs_from_txt(txt_f: str) -> list:
    rp_pidchains_lst_f = os.path.join('..', 'data', 'NMR', 'multimodel_lists', txt_f)
    if 'singlemod' == txt_f.split('_')[1]:
        with open(rp_pidchains_lst_f, 'r') as f:
            next(f)  # ignore first line
            pidchains = f.read().split()
    else:
        with open(rp_pidchains_lst_f, 'r') as f:
            pidchains = f.read().split('\n')
            pidchains = pidchains[:-1]
    rp_pdb_files = []
    PDB_dir = os.path.join('..', 'data', 'NMR', 'pdb_chains', 'hethom_combined')  # TODO update
    for pidchain in pidchains:
        rp_pdb_files.append(os.path.join(PDB_dir, f'{pidchain}.pdb'))
    return rp_pdb_files

op_sys = platform.system()  # 'Linux', 'Darwin' (Darwin = macOS), or 'Windows'
TMALIGN_BIN = os.path.join('utils', op_sys, 'TMalign')

def compute_tm(rp_pdb1, rp_pdb2):
    """
    Note: TM-score, unlike my RMSD calculation, does not take in arrays of coordinates.
    Instead, it expects (valid) PDB files.
    Compute TM-score between two pdb files.
    """

    try:
        result = subprocess.run(
            [TMALIGN_BIN, rp_pdb1, rp_pdb2],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            timeout=60
        )
        output = result.stdout
        for line in output.splitlines():
            if str(line).startswith('TM-score='):
                tm = float(line.split('=')[1].split()[0])
                return tm
    except Exception as e:
        print(f'Error computing TM-score for {rp_pdb1} vs {rp_pdb2}: {e}')
        return np.nan


def compute_tm_from_mp_pool(idx_pair, rp_all_pdb_files):
    """
    Takes a pair of integers, used as indexes to the list of PDB files (given as the relative path strings to the
    appropriate PDB/PDBchain files (which are expected to be single model, or a single mean of all models).)
    Compute TM-score between each pair of PDB/PDBchain files.
    """
    f1_idx, f2_idx = idx_pair
    f1 = rp_all_pdb_files[f1_idx]
    f2 = rp_all_pdb_files[f2_idx]
    f1_pdbname = os.path.basename(f1).removesuffix('.pdb')
    f2_pdbname = os.path.basename(f2).removesuffix('.pdb')

    assert Path(TMALIGN_BIN).exists(), f'{TMALIGN_BIN} does not exist'
    assert os.path.isfile(f1), f'{f1} not found'
    assert os.path.isfile(f2), f'{f2} not found'
    try:
        result = subprocess.run(
            [TMALIGN_BIN, f1, f2],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            timeout=60
        )
        output = result.stdout
        for line in output.splitlines():
            if line.startswith('TM-score='):
                tm = float(line.split('=')[1].split()[0])
                print(f'\nTM-score={tm} for {f1_pdbname}:{f2_pdbname}')
                return f1_pdbname, f2_pdbname, tm
    except Exception as e:
        print(f'Error computing TM-score for {f1} vs {f2}: {e}')
        return f1_idx, f2_idx, np.nan

def compute_tm_all_vs_all():
    # Generate all unique integer pair combinations (i < j) for above number of PDB files:
    N = 100 # intended to be the total number of pdb files
    rp_all_pdb_files = ''  # intended to be list of the rp_pdf_files
    pairs = list(itertools.combinations(range(N), 2))
    print(f'Total pairs to compute: {len(pairs)}')  # Total pairs to compute: ~10-50 (4-180)

    # Number of worker processes
    n_workers = max(cpu_count() - 1, 1)
    print(f'Using {n_workers} parallel workers.')  # Using 9 parallel workers.
    # Bind the extra argument
    # _compute_tm = partial(compute_tm, pdb_files=pdb_files_)
    _compute_tm = partial(compute_tm_from_mp_pool, rp_all_pdb_files=rp_all_pdb_files)
    # List to store only interesting results
    results = {'query': [], 'target': [], 'TMscore': []}
    # Simple heuristic: bigger groups → bigger chunks, but never below 1
    chunksize = max(1, len(pairs) // (4 * cpu_count()))
    # Optionally clamp to a reasonable upper bound
    chunksize = min(chunksize, 10)

    with Pool(processes=n_workers) as pool:
        for result_ in tqdm(
                pool.imap_unordered(_compute_tm, pairs, chunksize=10),
                total=len(pairs), desc="Processing TM-scores"
        ):
            pdb1, pdb2, tms = result_
            if np.isnan(tms):
                continue
            # if tm_ <= 0.8:
            results['query'].append(pdb1)
            results['target'].append(pdb2)
            results['TMscore'].append(tms)
    res_pdf = pd.DataFrame(results)
    res_pdf.to_csv(os.path.join('..', 'data', 'TM-scores.csv'), index=False)

    # Save interesting pairs as .npy
    rp_dst_tmalign_dir = _rp_tmscores_dir(sub_dir='multimod_2713_hetallchains_hom1chain')
    os.makedirs(rp_dst_tmalign_dir, exist_ok=True)
    rp_tm_pairs = os.path.join(rp_dst_tmalign_dir, 'all_vs_all_TMS.npy')
    print(f'Completed in {round((time() - start) / 60)} minutes.')


if __name__ == '__main__':

    # (NOTE: I DISCOVERED I COULD NOT RE-USE THE MEAN COORDS (NP ARRAYS) CALCULATED & USED IN COMPUTING RMSDS,
    # BECAUSE TM-ALIGN WANTS PDB FILE INPUTS ONLY.
    # SO, MEAN COORD PDBS FOR TM WERE CALCULATED BY BIOPTYHON VIA src/utils/pdb_chain_writer/write_mean_models_to_pdb(),
    # AND SAVED TO data/NMR/pdb_chains/multimod_2713_hetallchains_hom1chain/mean_coords.

    start = time()
    # # CALCULATE TM-SCORES OF EACH MODEL VS THE MEAN OF ALL MODELS:
    rp_pidc_2713_dir = os.path.join(_rp_nmr_dir(), 'pdb_chains', 'multimod_2713_hetallchains_hom1chain')
    rp_mean_coords_pidchains_dir = os.path.join(rp_pidc_2713_dir, 'mean_coords')
    rp_mean_coords_pidc_pdbs = sorted(glob.glob(os.path.join(rp_mean_coords_pidchains_dir, '*.pdb')))
    rp_permodel_pdb_dir = os.path.join(rp_pidc_2713_dir, 'per_model')

    for rp_mean_coords_pidc_pdb in rp_mean_coords_pidc_pdbs:
        tms_per_model = {'pidc': [], 'pidc_model': [], 'TM-score': [], 'min_TMS': [], 'max_TMS': [], 'mean_TMS': [], 'stdev_TMS': []}
        pidc_name = os.path.basename(rp_mean_coords_pidc_pdb).removesuffix('.pdb')
        print(pidc_name)
        # NOTE: TM-ALIGN RETURNS NONE FOR PROTEINS WITH LESS THAN 3 CA ATOMS:
        if (pidc_name == '1GAC_A' or pidc_name == '1GAC_B' or pidc_name == '1GAC_C' or pidc_name == '1GAC_D' or
                pidc_name == '1WCO_A' or pidc_name == '2AIZ_B' or pidc_name == '2K1Q_B' or pidc_name == '2M9P_B' or
                pidc_name == '2M9Q_B' or pidc_name == '2MX6_B' or pidc_name == '3CYS_B'):
            continue
        tm_scores = []
        rp_permodel_pidc_pdbs = sorted(glob.glob(os.path.join(rp_permodel_pdb_dir, pidc_name, '*.pdb')))
        for rp_permodel_pidc_pdb in rp_permodel_pidc_pdbs:
            tms = compute_tm(rp_pdb1=rp_permodel_pidc_pdb, rp_pdb2=rp_mean_coords_pidc_pdb)
            tms_per_model['pidc_model'].append(os.path.basename(rp_permodel_pidc_pdb).removesuffix('.pdb'))
            tm_scores.append(tms)

        # Note: I build the tms, but otherwise empty, dict & pdf first, to be able to sort by this before adding
        # the remaining, whcih are scalar or single string values, which are all on just the top line, otherwise
        # it'd look weird with these single row values randomly on a different line, with nans everywhere else:
        tms_per_model['TM-score'] = tm_scores
        empty_list = [np.nan for _ in tm_scores]
        tms_per_model['pidc'] = ['' for _ in tm_scores]
        tms_per_model['min_TMS'] = empty_list
        tms_per_model['max_TMS'] = empty_list
        tms_per_model['mean_TMS'] = empty_list
        tms_per_model['stdev_TMS'] = empty_list
        tms_pdf = pd.DataFrame(tms_per_model)
        tms_pdf = tms_pdf.sort_values(by=['TM-score'], ascending=[True])

        tms_pdf['pidc'] = [pidc_name] + ['' for _ in tm_scores][:-1]
        tms_pdf['min_TMS'] = [round(min(tm_scores), 4)] + empty_list[:-1]
        tms_pdf['max_TMS'] = [round(max(tm_scores), 4)] + empty_list[:-1]
        tms_pdf['mean_TMS'] = [round(statistics.mean(tm_scores), 4)] + empty_list[:-1]
        tms_pdf['stdev_TMS'] = [round(statistics.stdev(tm_scores), 4)] + empty_list[:-1]

        rp_pidc_dir = os.path.join(_rp_tmscores_dir(sub_dir='multimod_2713_hetallchains_hom1chain'))
        os.makedirs(rp_pidc_dir, exist_ok=True)
        tms_pdf.to_csv(os.path.join(rp_pidc_dir, f'TMS_{pidc_name}.csv'), index=False)
    print(f'Completed in {round((time() - start) / 60)} minutes.')
