# WARNING THIS SCRIPT IS ORIGINALLY GENERATED BY CHATGPT4o

# PATHS ARE EXPECTING THIS TO BE CALLED FROM DJ_Intern_Code/notebooks

import os
from time import time
from tqdm import tqdm
import subprocess
import itertools
import numpy as np
from multiprocessing import Pool, cpu_count
from functools import partial
import platform

op_sys = platform.system()  # 'Linux', 'Darwin' (Darwin = macOS), or 'Windows'
TMALIGN_BIN = os.path.join('utils', op_sys, 'TMalign')


def compute_tm(pair, pdb_files):
    i, j = pair
    f1 = pdb_files[i]
    f2 = pdb_files[j]
    try:
        result = subprocess.run(
            [TMALIGN_BIN, f1, f2],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            timeout=60
        )
        output = result.stdout
        for line in output.splitlines():
            if line.startswith('TM-score='):
                tm = float(line.split('=')[1].split()[0])
                return (i, j, tm)
    except Exception as e:
        print(f'Error computing TM-score for {f1} vs {f2}: {e}')
        return (i, j, np.nan)


if __name__ == '__main__':

    start = time()
    pdbid_chain = '1cvr_A'
    PDB_DIR = os.path.join('', 'data', 'ATLAS_parsed', pdbid_chain, 'CA_only')
    # PDB_DIR = os.path.join('..', 'data', 'ATLAS_parsed', pdbid_chain, 'test')

    pdb_files = sorted([
        os.path.join(PDB_DIR, f)
        for f in os.listdir(PDB_DIR)
        if f.endswith('.pdb')
    ])

    pdb_files_100_spread = [pdb_f for idx, pdb_f in enumerate(pdb_files) if idx % 100 == 0]
    assert(len(pdb_files_100_spread) == 101)

    # N = len(pdb_files)
    N = len(pdb_files_100_spread)
    print(f'Found {N} PDB files.')

    # Generate all unique pairs (i < j)
    pairs = list(itertools.combinations(range(N), 2))
    print(f'Total pairs to compute: {len(pairs)}')

    # Number of worker processes
    n_workers = max(cpu_count() - 1, 1)
    print(f'Using {n_workers} parallel workers.')

    # Bind the extra argument
    # _compute_tm = partial(compute_tm, pdb_files=pdb_files)
    _compute_tm = partial(compute_tm, pdb_files=pdb_files_100_spread)

    # List to store only interesting results
    interesting_results = []

    with Pool(processes=n_workers) as pool:
        for result in tqdm(
            pool.imap_unordered(_compute_tm, pairs, chunksize=10),
            total=len(pairs),
            desc="Processing TM-scores"
        ):
            i, j, tm = result
            if np.isnan(tm):
                continue
            if tm <= 0.8:
                interesting_results.append((i, j, tm))

    # Save interesting pairs as .npy
    rpath_tm_pairs = os.path.join('', 'data', 'ATLAS_parsed', pdbid_chain, 'low_tm_pairs.npy')
    np.save(rpath_tm_pairs, np.array(interesting_results, dtype=object))
    print(f"Saved {len(interesting_results)} pairs with TM-score < 0.8 to {rpath_tm_pairs}.")
    print(f'Completed in {round((time() - start)/60)} minutes.')
